{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load spread sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from typing import Iterable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from spreadsheet.\n",
    "data_frame = pd.read_excel(\n",
    "    '2019-08-27_PLASMA_DEFAULT_Results_Groningen.xlsx',\n",
    "    sheet_name=2,\n",
    ")\n",
    "\n",
    "# Load the phenotypes from SPSS file.\n",
    "phenotypes = pd.read_spss('phenotypes.sav')\n",
    "# Remove patients for which there is no sequencing data.\n",
    "phenotypes = phenotypes[~phenotypes['VAR00001'].isna()]\n",
    "# And set Patient ID as index.\n",
    "phenotypes['VAR00001'].name = 'Patient ID'\n",
    "phenotypes.set_index(phenotypes['VAR00001'].astype(int), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a fair comparison we should split the data in a training and validation set by randomly selecting patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of dataset we want to use for the validation set.\n",
    "f_val = 0.3\n",
    "\n",
    "patients = data_frame['Patient ID'].unique()\n",
    "np.random.shuffle(patients)\n",
    "\n",
    "# Determine the largest element no longer in the training set.\n",
    "cut_off = int(np.ceil(len(patients) * (1 - f_val)))\n",
    "train_patients = patients[:cut_off]\n",
    "test_patients = patients[cut_off:]\n",
    "\n",
    "# Put records in train/validation set according to \"Patient ID\".\n",
    "train_rows = data_frame['Patient ID'].isin(train_patients)\n",
    "train_data_frame = data_frame.loc[train_rows]\n",
    "test_data_frame = data_frame[~train_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated statistics\n",
    "Let us first look at the data as a whole (not just the training data), to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on the genes\n",
    "columns_to_keep = ['Patient ID', 'Gene']\n",
    "data_frame = data_frame[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurences of genes, regardless of how many per patient.\n",
    "gene_set = data_frame['Gene'].unique()\n",
    "gene_count  = data_frame.groupby('Gene') \\\n",
    "    .count()\n",
    "\n",
    "print(gene_set)\n",
    "# Plot occurences of genes, and make all genes with more than 3 instances red.\n",
    "gene_colour = gene_count['Patient ID'].apply(lambda x: 'red' if x > 5 else 'blue')\n",
    "ax = gene_count['Patient ID'].plot(kind='bar', color=gene_colour)\n",
    "ax.set_ylabel('# occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the majority of the mutations are unique, whilst the presence of TP53 is quite ubiquitous. \n",
    "\n",
    "How are the mutations distributed? One per patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many mutations per patient?\n",
    "mutation_counts = data_frame.groupby('Patient ID').count()\n",
    "ax = sns.distplot(mutation_counts, kde=False)\n",
    "ax.set_xlabel('# Mutations')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlim([1, max(mutation_counts['Gene'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above indicates that patients usually have one or two mutations. \n",
    "\n",
    "It can happen that there are multiple mutations in the same gene. \n",
    "How often does this occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many patients have more than 1 mutation in the same gene?\n",
    "# Group by (patient, gene):\n",
    "num_gene_mutations = data_frame.groupby(columns_to_keep) \\\n",
    "    .size() \\\n",
    "    .to_frame('size')\n",
    "# More than 1.\n",
    "same_gene_mutations = num_gene_mutations[num_gene_mutations['size'] > 1]\n",
    "\n",
    "# Fraction of total.\n",
    "num_patients_multi_mutation = len(same_gene_mutations.groupby('Patient ID'))\n",
    "num_patients = data_frame['Patient ID'].nunique()\n",
    "f = num_patients_multi_mutation / num_patients\n",
    "\n",
    "print('Number of patients with multiple mutations in same gene: {}/{} ({:.2f} %)'.format(\n",
    "    num_patients_multi_mutation, \n",
    "    num_patients, \n",
    "    f * 100.0),\n",
    ")\n",
    "\n",
    "same_gene_mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many mutations, and what mutations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of patients with at least two mutations.\n",
    "ax = sns.distplot(\n",
    "    same_gene_mutations, \n",
    "    kde=False,\n",
    "    bins=[2, 3, 4, 5],\n",
    ")\n",
    "ax.set_xlabel('# mutations in single gene')\n",
    "ax.set_ylabel('# patients')\n",
    "\n",
    "# Multiple mutations in same gene occurs almost solely in TP53.\n",
    "same_gene_mutations.groupby('Gene').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can borrow some tricks that are also used in text analysis. For example, in the bag-of-words approach one collects all words (the vocabulary) and counts the occurences of each word per text document. I will do the same below: with _gene_ $\\leftrightarrow$ _word_ and _text document_ $\\leftrightarrow$ _patient_. That is, for each patient (row) count the number of mutations per gene (column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_encode_mutations(\n",
    "    data_frame: pd.DataFrame, gene_vocabulary: Iterable\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dummy encode mutations for each patient.\n",
    "    \"\"\"\n",
    "    # Create an empty data frame first.\n",
    "    dummy_data_frame = pd.DataFrame(\n",
    "        0,\n",
    "        # Rows are patients\n",
    "        index=data_frame[\"Patient ID\"].unique(),\n",
    "        # Columns are the number of mutations per gene.\n",
    "        columns=gene_vocabulary,\n",
    "    )\n",
    "    dummy_data_frame.index.name = \"Patient ID\"\n",
    "\n",
    "    # Fill all columns with the number of occurences of each gene per patient.\n",
    "    for multi_index, patient_genes in data_frame.groupby([\"Patient ID\", \"Gene\"]):\n",
    "        # Unpack patient_id and the gene from the `MultiIndex`.\n",
    "        patient_id, gene = multi_index\n",
    "        # Store number of mutations of this particular gene.\n",
    "        dummy_data_frame.loc[patient_id][gene] += len(patient_genes)\n",
    "\n",
    "    return dummy_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary is the entire dataset, not only training set. Otherwise we run into problems during inference.\n",
    "gene_vocabulary = data_frame['Gene'].unique()\n",
    "\n",
    "dummy_data_frame = dummy_encode_mutations(train_data_frame, gene_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_to_keep = ['Clinical_Response', 'response_grouped', 'leeftijd']\n",
    "df_with_phenotype = pd.merge(\n",
    "    left=dummy_data_frame,\n",
    "    right=phenotypes[phenotypes_to_keep],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame['Patient ID'].unique()\n",
    "# train_data_frame.set_index('Patient ID').loc[1022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the code above is correct.\n",
    "assert dummy_data_frame.loc[1022]['TP53'] == 2\n",
    "assert dummy_data_frame.loc[1172]['TP53'] == 4\n",
    "assert dummy_data_frame.loc[1172]['STK11'] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-negative matrix factorisation\n",
    "$$X = WH$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_decomp = NMF(n_components=2).fit(dummy_data_frame)\n",
    "W = nmf_decomp.transform(dummy_data_frame)\n",
    "# Add jittering to help visualisation.\n",
    "W += np.random.normal(scale=0.025, size=W.shape)\n",
    "sns.scatterplot(W[:,0], W[:,1], hue=df_with_phenotype['Clinical_Response'] == 'SD', x_jitter=True, y_jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_decomp = PCA(n_components=2).fit(dummy_data_frame)\n",
    "L = pca_decomp.transform(dummy_data_frame)\n",
    "# Add jittering to help visualisation.\n",
    "L += np.random.normal(scale=0.075, size=L.shape)\n",
    "sns.scatterplot(L[:,0], L[:,1], hue=df_with_phenotype['Clinical_Response'] == 'SD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
