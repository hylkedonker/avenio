{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from source import load_avenio_files\n",
    "from transform import dummy_encode_mutations, mutation_train_test_split, patient_allele_frequencies\n",
    "\n",
    "\n",
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from spreadsheet and SPSS files.\n",
    "mutation_data_frame, phenotypes = load_avenio_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records for which there is no allele frequencies available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary is the entire dataset, not only training set. Otherwise we run into problems during inference.\n",
    "gene_vocabulary = mutation_data_frame['Gene'].unique()\n",
    "allele_columns = [\"T0: Allele \\nFraction\", \"T1: Allele Fraction\"]\n",
    "\n",
    "# 1) Convert to float.\n",
    "columns_to_numeric = allele_columns\n",
    "for column_name in allele_columns:\n",
    "    mutation_data_frame.loc[:, column_name] = pd.to_numeric(mutation_data_frame[column_name], errors='coerce')\n",
    "# 2) Drop rows for which the columns can not be converted.\n",
    "mutation_data_frame = mutation_data_frame.dropna(subset=allele_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of dataset we want to use for the validation set.\n",
    "f_val = 0.3\n",
    "# Split accordingly.\n",
    "train_mutations, test_mutations = mutation_train_test_split(\n",
    "    mutation_data_frame, test_fraction=f_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate allele frequency transformation for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_mutation_frequencies = patient_allele_frequencies(train_mutations, gene_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine calculated mutation data with phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_to_keep = ['Clinical_Response', 'response_grouped', 'leeftijd', 'progressie']\n",
    "df_with_phenotype = pd.merge(\n",
    "    left=patient_mutation_frequencies,\n",
    "    right=phenotypes[phenotypes_to_keep],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = 4\n",
    "X_pca = PCA(n_columns).fit_transform(patient_mutation_frequencies)\n",
    "X_pca += np.random.normal(scale=0.0025, size=X_pca.shape)\n",
    "sns.scatterplot(X_pca[:, 0], X_pca[:, 1], hue=df_with_phenotype['Clinical_Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed = TSNE(n_components=2, random_state=RANDOM_STATE).fit_transform(patient_mutation_frequencies)\n",
    "X_embed += np.random.normal(scale=0.25, size=X_embed.shape)\n",
    "sns.scatterplot(X_embed[:,0], X_embed[:,1], hue=df_with_phenotype['Clinical_Response'] == 'SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy encode phenotypes\n",
    "To dummy encode all phenotypes, just concatenate all the features into a string. Since all the words are unique, we can simply use the `CountVectorizer` for one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_hot_encode = [\n",
    "    \"gender\",\n",
    "    \"stage\",\n",
    "    \"therapyline\",\n",
    "    \"previoustherapy\",\n",
    "    \"Systemischetherapie\",\n",
    "    \"smokingstatus\",\n",
    "    \"histology_grouped\",\n",
    "    \"progressie\",\n",
    "]\n",
    "columns_numeric = [\n",
    "    \"leeftijd\",\n",
    "    \"lymfmeta\",\n",
    "    \"brainmeta\",\n",
    "    \"adrenalmeta\",\n",
    "    \"livermeta\",\n",
    "    \"lungmeta\",\n",
    "    \"skeletometa\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data.\n",
    "empty_previous_therapy = phenotypes['previoustherapy'] == ''\n",
    "phenotypes.loc[empty_previous_therapy, 'previoustherapy'] = 'unknown_therapy'\n",
    "\n",
    "# Map numbers to words.\n",
    "phenotypes['stage'] = phenotypes['stage'].astype(int) \\\n",
    "    .apply(lambda x: 'stage{}'.format(x))\n",
    "phenotypes['therapyline'] = phenotypes['therapyline'].astype(int) \\\n",
    "    .apply(lambda x: 'line{}'.format(x))\n",
    "phenotypes['progressie'] = phenotypes['progressie'].astype(int) \\\n",
    "    .map({0: 'noprogress', 1: 'progress'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all the phenotypes to a string (collection of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_as_str = [\n",
    "    \" \".join(patient_data)\n",
    "    for _, patient_data in phenotypes[columns_to_hot_encode].iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a simple pipeline to one-hot-encode the data and decompose using NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise operations to carry out.\n",
    "n_components = 4\n",
    "vectoriser = CountVectorizer()\n",
    "nmf_decomp = NMF(n_components)\n",
    "pca_decomp = PCA(n_components)\n",
    "\n",
    "# Do the transformations: count and decompose.\n",
    "X_pheno_hot = vectoriser.fit_transform(phenotype_as_str)\n",
    "# Decompose using NMF.\n",
    "W = nmf_decomp.fit_transform(X_pheno_hot)\n",
    "H = nmf_decomp.components_\n",
    "# Decompose using PCA.\n",
    "X_pca = pca_decomp.fit_transform(X_pheno_hot.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using t-SNE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed = TSNE(n_components=2).fit_transform(X_pheno_hot.toarray())\n",
    "sns.scatterplot(X_embed[:,0], X_embed[:, 1], hue=phenotypes['response_grouped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phenotypes['progressie'].value_counts())\n",
    "print('--' * 10)\n",
    "print(phenotypes['Clinical_Response'].value_counts())\n",
    "print('--' * 10)\n",
    "print(phenotypes['response_grouped'].value_counts())\n",
    "print('--' * 10)\n",
    "print(phenotypes['progressie'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jittering to help visualisation.\n",
    "W_jit = W + np.random.normal(scale=0.025, size=W.shape)\n",
    "X_pca_jit = X_pca + np.random.normal(scale=0.025, size=X_pca.shape)\n",
    "\n",
    "for i in range(n_components):\n",
    "    for j in range(i + 1, n_components):\n",
    "        plt.figure()\n",
    "        plt.title('({}, {})'.format(i, j))\n",
    "        plt.xlabel(r'$W_{i' + str(i) + '}$')\n",
    "        plt.ylabel(r'$W_{i' + str(j) + '}$')\n",
    "#         sns.scatterplot(W_jit[:,i], W_jit[:,j], hue=phenotypes['Clinical_Response'], x_jitter=True, y_jitter=True)\n",
    "        sns.scatterplot(W_jit[:,i], W_jit[:,j], hue=phenotypes['response_grouped'], x_jitter=True, y_jitter=True)\n",
    "#         sns.scatterplot(X_pca_jit[:,i], X_pca_jit[:,j], hue=phenotypes['Clinical_Response'], x_jitter=True, y_jitter=True)\n",
    "#         sns.scatterplot(W_jit[:,i], W_jit[:,j], hue=phenotypes['progressie'], x_jitter=True, y_jitter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
