{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final classifier using mutant concentration\n",
    "**Goal**: Identify patients that don't respond.\n",
    "These patients we don't have to treat.\n",
    "\n",
    "Perform the following steps:\n",
    "\n",
    "1) Combine data with CNV.\n",
    "\n",
    "2) Compare harmonic versus delta.\n",
    "\n",
    "3) Compare clinical data versus clinical and genomic data.\n",
    "\n",
    "4) Select best classification model based on AUC.\n",
    "\n",
    "5) For this best model, compare number of molecules.\n",
    "\n",
    "7) Make plots for parameter importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from pipelines import benchmark_pipelines, build_classifier_pipelines, pipeline_Freeman, get_classifier_init_params\n",
    "from transform import generate_data_pairs, generate_model_data_pairs\n",
    "from views import compare_prognostic_value_genomic_information, view_linear_model_freeman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import read_preprocessed_data\n",
    "from transform import combine_tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference genomic variable.\n",
    "X_diff, y = combine_tsv_files(\n",
    "    \"output/all__gene__difference__No. Mutant Molecules per mL.tsv\",\n",
    "    \"output/all__gene__difference__CNV Score.tsv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resp = y[\"response_grouped\"]\n",
    "\n",
    "response_labels = ['non responder (sd+pd)', 'responder (pr+cr)', 'non evaluable (ne)']\n",
    "pos_label = 'responder (pr+cr)'\n",
    "y_resp = y_resp == pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_class = build_classifier_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "DummyClassifier(random_state=1234, strategy='most_frequent') :\n",
      "params: {}\n",
      "\n",
      "--------------------\n",
      "DummyClassifier(random_state=1234, strategy='most_frequent') :\n",
      "params: {'statistical_filter__alpha': [0.05, 0.1, 0.2, 0.4]}\n",
      "\n",
      "Removing 68/69 numeric columns.\n",
      "Removing 67/69 numeric columns.\n",
      "Removing 67/69 numeric columns.\n",
      "Removing 68/69 numeric columns.\n",
      "Removing 65/69 numeric columns.\n",
      "--------------------\n",
      "DummyClassifier(random_state=1234, strategy='most_frequent') :\n",
      "params: {}\n",
      "\n",
      "--------------------\n",
      "LogisticRegression(class_weight='balanced', max_iter=5000, random_state=1234,\n",
      "                   solver='newton-cg') :\n",
      "params: {'estimator__C': [0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.175, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 4.0]}\n",
      "\n",
      "--------------------\n",
      "LogisticRegression(class_weight='balanced', max_iter=5000, random_state=1234,\n",
      "                   solver='newton-cg') :\n",
      "params: {'statistical_filter__alpha': [0.05, 0.1, 0.2, 0.4], 'estimator__C': [0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.175, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 4.0]}\n",
      "\n",
      "Removing 56/69 numeric columns.\n",
      "Removing 54/69 numeric columns.\n",
      "Removing 47/69 numeric columns.\n",
      "Removing 51/69 numeric columns.\n",
      "Removing 58/69 numeric columns.\n",
      "--------------------\n",
      "LogisticRegression(class_weight='balanced', max_iter=5000, random_state=1234,\n",
      "                   solver='newton-cg') :\n",
      "params: {'estimator__C': [0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.175, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 4.0]}\n",
      "\n",
      "--------------------\n",
      "DecisionTreeClassifier(class_weight='balanced', random_state=1234) :\n",
      "params: {'estimator__max_depth': [2, 3, 5, 7, 10, 15, 20], 'estimator__criterion': ['gini', 'entropy']}\n",
      "\n",
      "--------------------\n",
      "DecisionTreeClassifier(class_weight='balanced', random_state=1234) :\n",
      "params: {'statistical_filter__alpha': [0.05, 0.1, 0.2, 0.4], 'estimator__max_depth': [2, 3, 5, 7, 10, 15, 20], 'estimator__criterion': ['gini', 'entropy']}\n",
      "\n",
      "Removing 48/69 numeric columns.\n",
      "Removing 46/69 numeric columns.\n",
      "Removing 57/69 numeric columns.\n",
      "Removing 54/69 numeric columns.\n",
      "Removing 45/69 numeric columns.\n",
      "--------------------\n",
      "DecisionTreeClassifier(class_weight='balanced', random_state=1234) :\n",
      "params: {'estimator__max_depth': [2, 3, 5, 7, 10, 15, 20], 'estimator__criterion': ['gini', 'entropy']}\n",
      "\n",
      "--------------------\n",
      "RandomForestClassifier(random_state=1234) :\n",
      "params: {'estimator__n_estimators': [15, 30, 50, 100], 'estimator__max_depth': [2, 3, 5, 7, 10, 15, None], 'estimator__class_weight': ['balanced', 'balanced_subsample']}\n",
      "\n",
      "--------------------\n",
      "RandomForestClassifier(random_state=1234) :\n",
      "params: {'statistical_filter__alpha': [0.05, 0.1, 0.2, 0.4], 'estimator__n_estimators': [15, 30, 50, 100], 'estimator__max_depth': [2, 3, 5, 7, 10, 15, None], 'estimator__class_weight': ['balanced', 'balanced_subsample']}\n",
      "\n",
      "Removing 48/69 numeric columns.\n",
      "Removing 46/69 numeric columns.\n",
      "Removing 57/69 numeric columns.\n",
      "Removing 54/69 numeric columns.\n",
      "Removing 45/69 numeric columns.\n",
      "--------------------\n",
      "RandomForestClassifier(random_state=1234) :\n",
      "params: {'estimator__n_estimators': [15, 30, 50, 100], 'estimator__max_depth': [2, 3, 5, 7, 10, 15, None], 'estimator__class_weight': ['balanced', 'balanced_subsample']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance using nested loop cross validation.\n",
    "b_difference = benchmark_pipelines(\n",
    "    ps_class, X_diff, y_resp, metric='roc_auc', verbose=False,\n",
    ")\n",
    "b_difference.to_csv(\"difference_molecules_benchmask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_difference = pd.read_csv('difference_molecules_benchmask.csv')\n",
    "b_difference.set_index('Unnamed: 0', inplace=True)\n",
    "b_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction with difference instead of harmonic mean is therefore marginally worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b_difference\n",
    "plt.rc('font', family='serif')\n",
    "import matplotlib\n",
    "context = {\n",
    "#     'font.size': 22,\n",
    "    'lines.linewidth': 4,\n",
    "    'figure.autolayout': True,\n",
    "    'xtick.labelsize': 'large',\n",
    "    'ytick.labelsize': 'large',\n",
    "    'legend.fontsize': 'x-large',\n",
    "    'axes.labelsize': 'xx-large',\n",
    "    'axes.titlesize': 'xx-large',\n",
    "}\n",
    "# fig = plt.figure(figsize=(4, 3))\n",
    "with plt.rc_context(context):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    degrees=75\n",
    "    plt.ylabel('AUC ROC')\n",
    "    plt.xticks(rotation=degrees)\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.gca().fill_between([-1, 8], 0, 0.5, facecolor='grey', edgecolor='k', alpha=0.25, hatch='\\\\')\n",
    "    plt.errorbar(\n",
    "        b.index, \n",
    "        b['Richard mean'], \n",
    "        yerr=b['Richard std'], \n",
    "        fmt='s-', \n",
    "        markersize=10,\n",
    "        label='clinical',\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        b.index, \n",
    "        b['Freeman mean'], \n",
    "        yerr=b['Freeman std'], \n",
    "        fmt='o--', \n",
    "        markersize=10,\n",
    "        label='clinical + genomic',\n",
    "    )\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "plt.savefig('figs/comparison_classifiers.png', bbox_inches = 'tight')\n",
    "plt.savefig('figs/comparison_classifiers.eps', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Choose model logistic regression.\n",
    "The logistic regression model doesn't have the best accuracy in absolute terms, but is much simpler than the RandomForest. So by occams razor, we pick it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=1234\n",
    "\n",
    "Estimator = LogisticRegression\n",
    "kwargs = get_classifier_init_params(Estimator, random_state=random_state)\n",
    "model = pipeline_Freeman(Estimator(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Make plots of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_filenames = (\"logistic_regression_clinical_freeman\", \"logistic_regression_genetic_freeman\")\n",
    "view_linear_model_freeman(\n",
    "    X_diff, \n",
    "    y_resp, \n",
    "    model, \n",
    "    filenames=figure_filenames, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amount of genetic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=1234\n",
    "\n",
    "Estimator = LogisticRegression\n",
    "kwargs = get_classifier_init_params(Estimator, random_state=random_state)\n",
    "classifier = Estimator(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_data_pairs = generate_data_pairs(\n",
    "    filename_prefix=\"output/all__gene\", snv_type=\"No. Mutant Molecules per mL\"\n",
    ")\n",
    "vaf_data_pairs = generate_data_pairs(\n",
    "    filename_prefix=\"output/all__gene\", snv_type=\"Allele Fraction\"\n",
    ")\n",
    "model_mutant_data_pairs = generate_model_data_pairs(mutant_data_pairs, model=classifier)\n",
    "model_vaf_data_pairs = generate_model_data_pairs(vaf_data_pairs, model=classifier)\n",
    "compare_prognostic_value_genomic_information(model_mutant_data_pairs, plot_label=\"Mutant concentration\", fmt='-')\n",
    "compare_prognostic_value_genomic_information(model_vaf_data_pairs, plot_label='Allele fraction', fmt='--')\n",
    "plt.savefig('figs/comparison_genomic_data.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
