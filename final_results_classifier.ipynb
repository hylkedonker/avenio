{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final classifier using harmonic mean\n",
    "**Goal**: Identify patients that don't respond.\n",
    "These patients we don't have to treat.\n",
    "\n",
    "Perform the following steps:\n",
    "\n",
    "1) Combine data with CNV.\n",
    "\n",
    "2) Compare harmonic versus delta.\n",
    "\n",
    "3) Compare clinical data versus clinical and genomic data.\n",
    "\n",
    "4) Select best classification model based on AUC.\n",
    "\n",
    "5) For this best model, compare number of molecules.\n",
    "\n",
    "6) Perform cross validation.\n",
    "\n",
    "7) Make plots for parameter importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from pipelines import benchmark_pipelines, build_classifier_pipelines, pipeline_Freeman\n",
    "from views import view_linear_model_freeman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import read_preprocessed_data\n",
    "from transform import combine_tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonic mean genomic variable.\n",
    "X_train_hm, y_train_hm = combine_tsv_files(\n",
    "    \"output/train__harmonic_mean__No. Mutant Molecules per mL.tsv\",\n",
    "    \"output/train__harmonic_mean__CNV Score.tsv\",\n",
    ")\n",
    "# Difference genomic variable.\n",
    "X_train_diff, y_train_diff = combine_tsv_files(\n",
    "    \"output/train__difference__No. Mutant Molecules per mL.tsv\",\n",
    "    \"output/train__difference__CNV Score.tsv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resp = y_train_hm[\"response_grouped\"]\n",
    "\n",
    "response_labels = ['non responder (sd+pd)', 'responder (pr+cr)', 'non evaluable (ne)']\n",
    "pos_label = 'responder (pr+cr)'\n",
    "y_train_resp = y_train_resp == pos_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_class = build_classifier_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sub_pipeline\n",
    "p_sub = get_sub_pipeline(ps_class['LogisticRegression']['Freeman'], 3)\n",
    "p_sub.fit_transform(X_train_hm, y_train_resp)\n",
    "# ps_class['LogisticRegression']['Richard'].fit_transform(X_train_hm, y_train_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_difference = benchmark_pipelines(\n",
    "    ps_class, X_train_diff, y_train_resp, metric='roc_auc',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_harmonic_mean = benchmark_pipelines(\n",
    "    ps_class, X_train_hm, y_train_resp, metric='roc_auc',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_harmonic_mean\n",
    "# print(b.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On average harmonic mean is better by', (b_harmonic_mean.mean(axis=1) - b_difference.mean(axis=1)).mean(), 'ROC AUC')\n",
    "b_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction with difference instead of harmonic mean is therefore marginally worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b_harmonic_mean\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "degrees=75\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xticks(rotation=degrees)\n",
    "plt.ylim([0, 1])\n",
    "plt.gca().fill_between([-1, 8], 0, 0.5, facecolor='grey', edgecolor='k', alpha=0.25, hatch='\\\\')\n",
    "plt.errorbar(b.index, b['Richard mean'], yerr=b['Richard std'], label='clinical')\n",
    "plt.errorbar(b.index, b['Freeman mean'], yerr=b['Freeman std'], label='clinical + genomic')\n",
    "plt.legend(frameon=False)\n",
    "# plt.tight_layout()\n",
    "plt.savefig('figs/comparison_classifiers.png', bbox_inches = 'tight')\n",
    "plt.savefig('figs/comparison_classifiers.eps', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Choose model logistic regression.\n",
    "The logistic regression model doesn't have the best accuracy in absolute terms, but is much simpler than the RandomForest. So by occams razor, we pick it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=1234\n",
    "logistic_Freeman_parameters = {\n",
    "    \"random_state\": random_state,\n",
    "#     \"penalty\": \"l2\",\n",
    "#     \"class_weight\": \"balanced\",\n",
    "    \"solver\": \"newton-cg\",\n",
    "#     \"C\": 1.0,\n",
    "#     \"max_iter\": 10000,\n",
    "#     'tol': 0.00001,\n",
    "}\n",
    "logistic_Freeman = pipeline_Freeman(LogisticRegression, **logistic_Freeman_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Cross validation\n",
    "Find the optimal hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_hyper_parameters = {\n",
    "#     \"filter_rare_mutations__top_k_features\": (4, 5, 6, 7, 8, 10, 12, 18, 24, 48),\n",
    "    \"estimator__C\": [0.025, 0.05, 0.075, 0.1, 0.175, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 4.0],\n",
    "    \"estimator__class_weight\": [\"balanced\", None],\n",
    "}\n",
    "clf_search = GridSearchCV(\n",
    "    logistic_Freeman,\n",
    "    logistic_regression_hyper_parameters,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=8,\n",
    "    cv=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_search.fit(X_train_hm, y_train_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf_search.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf_search.cv_results_['mean_test_score']\n",
    "stds = clf_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Non-convergent best parameters under elasticnet.\n",
    "# best_params = {\n",
    "#     'estimator__C': 2.0,\n",
    "#     'estimator__class_weight': None,\n",
    "#     'estimator__l1_ratio': 0.025,\n",
    "#     \"estimator__penalty\": \"l1\",\n",
    "#     \"estimator__solver\": \"saga\",\n",
    "#     'filter_rare_mutations__top_k_features': 4,\n",
    "#     'transform_columns__age_discretizer__n_bins': 2,\n",
    "# }\n",
    "\n",
    "# Best parameters under L2 norm.\n",
    "best_params = {\n",
    "    \"estimator__C\": 0.1,\n",
    "    \"estimator__class_weight\": \"balanced\",\n",
    "    \"estimator__solver\": \"newton-cg\",\n",
    "#     \"estimator__solver\": \"saga\",\n",
    "#     \"filter_rare_mutations__top_k_features\": 5,\n",
    "#     \"transform_columns__age_discretizer__n_bins\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert best_params == clf_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best parameteres.\n",
    "logistic_Freeman.set_params(**best_params)\n",
    "logistic_Freeman.fit(X_train_hm, y_train_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Make plots of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_filenames = (\"logistic_regression_clinical_freeman\", \"logistic_regression_genetic_freeman\")\n",
    "view_linear_model_freeman(\n",
    "    X_train_diff, \n",
    "    y_train_resp, \n",
    "    logistic_Freeman, \n",
    "    filenames=figure_filenames, \n",
    "    thresshold=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
