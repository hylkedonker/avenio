{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load spread sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from source import load_avenio_files\n",
    "from transform import dummy_encode_mutations, mutation_train_test_split\n",
    "\n",
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from spreadsheet and SPSS files.\n",
    "mutation_data_frame, phenotypes = load_avenio_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a fair comparison we should split the data in a training and validation set by randomly selecting patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of dataset we want to use for the validation set.\n",
    "f_val = 0.3\n",
    "# Split accordingly.\n",
    "train_mutations, test_mutations = mutation_train_test_split(\n",
    "    mutation_data_frame, test_fraction=f_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated statistics mutation\n",
    "Let us first look at the data as a whole (not just the training data), to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus only on the genes\n",
    "columns_to_keep = ['Patient ID', 'Gene']\n",
    "mutation_data_frame = mutation_data_frame[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurences of genes, regardless of how many per patient.\n",
    "gene_set = mutation_data_frame['Gene'].unique()\n",
    "gene_count  = mutation_data_frame.groupby('Gene') \\\n",
    "    .count()\n",
    "\n",
    "print(gene_count)\n",
    "\n",
    "print(gene_set)\n",
    "# Plot occurences of genes, and make all genes with more than 3 instances red.\n",
    "gene_colour = gene_count['Patient ID'].apply(lambda x: 'red' if x > 5 else 'blue')\n",
    "ax = gene_count['Patient ID'].plot(kind='bar', color=gene_colour)\n",
    "ax.set_ylabel('# occurences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the majority of the mutations are unique, whilst the presence of TP53 is quite ubiquitous. \n",
    "\n",
    "How are the mutations distributed? One per patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many mutations per patient?\n",
    "mutation_counts = mutation_data_frame.groupby('Patient ID').count()\n",
    "ax = sns.distplot(mutation_counts, kde=False)\n",
    "ax.set_xlabel('# Mutations')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_xlim([1, max(mutation_counts['Gene'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above indicates that patients usually have one or two mutations. \n",
    "\n",
    "It can happen that there are multiple mutations in the same gene. \n",
    "How often does this occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many patients have more than 1 mutation in the same gene?\n",
    "# Group by (patient, gene):\n",
    "num_gene_mutations = mutation_data_frame.groupby(columns_to_keep) \\\n",
    "    .size() \\\n",
    "    .to_frame('size')\n",
    "# More than 1.\n",
    "same_gene_mutations = num_gene_mutations[num_gene_mutations['size'] > 1]\n",
    "\n",
    "# Fraction of total.\n",
    "num_patients_multi_mutation = len(same_gene_mutations.groupby('Patient ID'))\n",
    "num_patients = mutation_data_frame['Patient ID'].nunique()\n",
    "f = num_patients_multi_mutation / num_patients\n",
    "\n",
    "print('Number of patients with multiple mutations in same gene: {}/{} ({:.2f} %)'.format(\n",
    "    num_patients_multi_mutation, \n",
    "    num_patients, \n",
    "    f * 100.0),\n",
    ")\n",
    "\n",
    "same_gene_mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many mutations, and what mutations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of patients with at least two mutations.\n",
    "ax = sns.distplot(\n",
    "    same_gene_mutations, \n",
    "    kde=False,\n",
    "    bins=[2, 3, 4, 5],\n",
    ")\n",
    "ax.set_xlabel('# mutations in single gene')\n",
    "ax.set_ylabel('# patients')\n",
    "\n",
    "# Multiple mutations in same gene occurs almost solely in TP53.\n",
    "same_gene_mutations.groupby('Gene').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes.columns[:20]\n",
    "features_to_investigate = ['gender', 'leeftijd', 'stage', 'smokingstatus', 'histology_grouped', 'metastasescount']\n",
    "sns.pairplot(phenotypes[features_to_investigate], hue='gender')\n",
    "sns.pairplot(phenotypes[features_to_investigate], hue='histology_grouped')\n",
    "sns.pairplot(phenotypes[features_to_investigate], hue='smokingstatus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can borrow some tricks that are also used in text analysis. For example, in the bag-of-words approach one collects all words (the vocabulary) and counts the occurences of each word per text document. I will do the same below: with _gene_ $\\leftrightarrow$ _word_ and _text document_ $\\leftrightarrow$ _patient_. That is, for each patient (row) count the number of mutations per gene (column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary is the entire dataset, not only training set. Otherwise we run into problems during inference.\n",
    "gene_vocabulary = mutation_data_frame['Gene'].unique()\n",
    "\n",
    "dummy_data_frame = dummy_encode_mutations(train_mutations, gene_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine with phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_to_keep = ['Clinical_Response', 'response_grouped', 'leeftijd', 'progressie']\n",
    "df_with_phenotype = pd.merge(\n",
    "    left=dummy_data_frame,\n",
    "    right=phenotypes[phenotypes_to_keep],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mutations['Patient ID'].unique()\n",
    "# train_data_frame.set_index('Patient ID').loc[1022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that the code above is correct.\n",
    "assert dummy_data_frame.loc[1022]['TP53'] == 2\n",
    "assert dummy_data_frame.loc[1172]['TP53'] == 4\n",
    "assert dummy_data_frame.loc[1172]['STK11'] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition on counts\n",
    "Let us first do a decomposition using non-negative matrix factorisation (NMF):\n",
    "$$X = WH$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "nmf_decomp = NMF(n_components).fit(dummy_data_frame)\n",
    "W = nmf_decomp.transform(dummy_data_frame)\n",
    "H = nmf_decomp.components_\n",
    "\n",
    "# Add jittering to help visualisation.\n",
    "W_jit = W + np.random.normal(scale=0.025, size=W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(0, H.shape[1]))\n",
    "ax.set_yticklabels(dummy_data_frame.columns)\n",
    "plt.imshow(H.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that the components are completely determined by the presence of TP53 and KRAS.\n",
    "\n",
    "Now lets zoom in on the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jittering to help visualisation.\n",
    "non_response = (df_with_phenotype['Clinical_Response'] == 'SD') | (df_with_phenotype['Clinical_Response'] == 'PD')\n",
    "for i in range(n_components):\n",
    "    for j in range(i + 1, n_components):\n",
    "        plt.figure()\n",
    "        plt.title('({}, {})'.format(i, j))\n",
    "        plt.xlabel(r'$W_{i' + str(i) + '}$')\n",
    "        plt.ylabel(r'$W_{i' + str(j) + '}$')\n",
    "        sns.scatterplot(W_jit[:,i], W_jit[:,j], hue=non_response, x_jitter=True, y_jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In turns out that patients with stable disease (SD)have no KRAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_components):\n",
    "    for j in range(i + 1, n_components):\n",
    "        plt.figure()\n",
    "        plt.title('({}, {})'.format(i, j))\n",
    "        plt.xlabel(r'$W_{i' + str(i) + '}$')\n",
    "        plt.ylabel(r'$W_{i' + str(j) + '}$')\n",
    "        sns.scatterplot(W_jit[:, i], W_jit[:, j], hue=df_with_phenotype['Clinical_Response'] == 'SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "PCA essentially gives the same results as NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_decomp = PCA(n_components=2).fit(dummy_data_frame)\n",
    "L = pca_decomp.transform(dummy_data_frame)\n",
    "# Add jittering to help visualisation.\n",
    "L += np.random.normal(scale=0.075, size=L.shape)\n",
    "sns.scatterplot(L[:,0], L[:,1], hue=df_with_phenotype['Clinical_Response'] == 'SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embed = TSNE(n_components=2).fit_transform(dummy_data_frame)\n",
    "sns.scatterplot(X_embed[:,0], X_embed[:,1], hue=df_with_phenotype['Clinical_Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency - inverse document frequency (TF-IDF)\n",
    "Since the matrix decomposition is completely dominated by TP53 and KRAS, let us use TF-IDF to help find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "X_tfidf = TfidfTransformer().fit_transform(dummy_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dummy_data_frame.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same NMF trick again and see if the result differ substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "nmf_decomp = NMF(n_components).fit(X_tfidf)\n",
    "W_tfidf = nmf_decomp.transform(X_tfidf)\n",
    "H_tfidf = nmf_decomp.components_\n",
    "\n",
    "# Add jittering to help visualisation.\n",
    "W_jit2 = W_tfidf + np.random.normal(scale=0.025, size=W_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(0, H_tfidf.shape[1]))\n",
    "ax.set_yticklabels(dummy_data_frame.columns)\n",
    "plt.imshow(H_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add jittering to help visualisation.\n",
    "for i in range(n_components):\n",
    "    for j in range(i + 1, n_components):\n",
    "        plt.figure()\n",
    "        plt.title('({}, {})'.format(i, j))\n",
    "        plt.xlabel(r'$W_{i' + str(i) + '}$')\n",
    "        plt.ylabel(r'$W_{i' + str(j) + '}$')\n",
    "        plt.title('Grouped response')\n",
    "        sns.scatterplot(W_jit2[:,i], W_jit2[:,j], hue=df_with_phenotype['response_grouped'], x_jitter=True, y_jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_components):\n",
    "    for j in range(i + 1, n_components):\n",
    "        plt.figure()\n",
    "        plt.title('({}, {})'.format(i, j))\n",
    "        plt.xlabel(r'$W_{i' + str(i) + '}$')\n",
    "        plt.ylabel(r'$W_{i' + str(j) + '}$')\n",
    "        sns.scatterplot(W_jit2[:, i], W_jit2[:, j], hue=df_with_phenotype['Clinical_Response'] == 'SD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
